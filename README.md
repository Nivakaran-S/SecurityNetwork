# ğŸ›¡ï¸ Network Security Threat Detection

A **machine learningâ€“driven** network security monitoring system designed to **detect potential threats** by analyzing incoming network activity data.  
The project follows a **component-based modular architecture** to ensure scalability, maintainability, and ease of integration with other systems.

It uses **FastAPI** for serving prediction and training endpoints, **MongoDB** for data storage, and **MLflow** to track model training metrics and versions.

---

## ğŸ“Œ Features

- **Modular ML Pipeline**  
  Separate components for:
  - Data Ingestion  
  - Data Validation  
  - Data Transformation  
  - Model Training

- **API Endpoints with FastAPI**  
  - `/train` â†’ Triggers the ML pipeline for training.  
  - `/predict` â†’ Upload a CSV file and get predictions with threat classification.

- **Database Integration**  
  - Uses MongoDB to store ingested network security data.
  - Configurable connection via environment variables.

- **MLflow Integration**  
  - Tracks experiments, metrics, and models during training.
  - Ensures reproducibility and easier model comparison.

- **CORS Enabled**  
  Fully accessible from different frontend applications.

- **Preprocessor & Model Persistence**  
  - Saves trained preprocessor and model objects as `.pkl` files.
  - Reloads them at prediction time for consistent data handling.

---

## ğŸ—ï¸ Project Structure
```bash

networksecurity/
â”‚
â”œâ”€â”€ components/ # Core pipeline components
â”‚ â”œâ”€â”€ data_ingestion.py
â”‚ â”œâ”€â”€ data_validation.py
â”‚ â”œâ”€â”€ data_transformation.py
â”‚ â””â”€â”€ model_trainer.py
â”‚
â”œâ”€â”€ constants/ # Static configuration constants
â”‚
â”œâ”€â”€ entity/ # Configuration and artifact entities
â”‚
â”œâ”€â”€ exception/ # Custom exception handling
â”‚
â”œâ”€â”€ logging/ # Centralized logging setup
â”‚
â”œâ”€â”€ pipeline/ # Orchestration for full training run
â”‚ â””â”€â”€ training_pipeline.py
â”‚
â”œâ”€â”€ utils/ # Utility functions (ML, file handling)
â”‚
templates/
â”‚ â””â”€â”€ table.html # HTML template for prediction output
final_model/
â”‚ â”œâ”€â”€ model.pkl # Trained ML model
â”‚ â””â”€â”€ preprocessor.pkl # Data transformation pipeline
prediction_output/
â”‚ â””â”€â”€ output.csv # CSV with predictions

```

---

## âš™ï¸ Tech Stack

- **Programming Language:** Python
- **Frameworks & Libraries:**  
  - FastAPI  
  - Pandas  
  - scikit-learn  
  - pymongo  
  - MLflow
- **Database:** MongoDB
- **Environment Management:** python-dotenv
- **Model Tracking:** MLflow
- **Web Templating:** Jinja2
- **Deployment Ready:** Uvicorn ASGI server

---

## ğŸš€ How It Works

1. **Training Phase**
   - Data is ingested from MongoDB.
   - Data validation checks for schema and quality.
   - Data is transformed and preprocessed.
   - Model is trained and tracked via **MLflow**.
   - Trained model and preprocessor are saved locally.

2. **Prediction Phase**
   - User uploads a `.csv` file through `/predict` endpoint.
   - Data is transformed using the saved preprocessor.
   - Predictions are generated using the trained model.
   - Results are displayed as an HTML table and saved as `prediction_output/output.csv`.

---

## ğŸ“‚ API Endpoints

| Method | Endpoint    | Description |
|--------|------------|-------------|
| GET    | `/`         | Redirects to FastAPI docs |
| GET    | `/train`    | Triggers model training pipeline |
| POST   | `/predict`  | Upload CSV for predictions |

---

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash

git clone https://github.com/Nivakaran-S/SecurityNetwork.git
cd <your-project-folder>

```

### 2ï¸âƒ£ Create a virtual environment

```bash

python -m venv venv
source venv/bin/activate  # For Linux/Mac
venv\Scripts\activate     # For Windows

```

### 3ï¸âƒ£ Install dependencies

```bash

pip install -r requirements.txt

```

### 4ï¸âƒ£ Set up environment variables
Create a .env file in the project root:

```bash

MONGODB_URL_KEY=<your-mongodb-connection-string>

```
### 5ï¸âƒ£ Run the application

```bash

python app.py

```

The API will be available at:

```bash

http://0.0.0.0:8000

```

You can explore interactive documentation at:

```bash

http://0.0.0.0:8000/docs

```

## ğŸ“Š MLflow Usage
1. Start MLflow Tracking UI:

```bash

mlflow ui

```

2. Open in browser:

```bash

http://127.0.0.1:5000

```

3. View experiments, compare metrics, and download models.

## ğŸ“Œ Example Prediction Flow
1. Send a POST request to /predict with a CSV file.

2. The server:
- Loads saved preprocessor and model.
- Generates predictions.
- Returns results as an HTML table.

3. Output is also stored in prediction_output/output.csv.

## ğŸ›¡ï¸ Error Handling
- All exceptions are wrapped in a custom NetworkSecurityException class.
- Detailed logs are maintained for debugging.
- Failures in any pipeline stage are reported clearly.

